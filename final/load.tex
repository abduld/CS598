\subsection{Processor Utilization}


\begin{figure*}[htp]
  \centering

  \begin{subfigure}[b]{\textwidth}
          \centering
          \includegraphics[width=0.4\textwidth]{data/load_legend.pdf}
  \end{subfigure}

  \begin{subfigure}[b]{0.85\textwidth}
       \centering
       \includegraphics[width=\textwidth]{data/load_vectoradd_nexus5.pdf}
       \caption{VectorAdd on Nexus 5}\label{fig:Vecadd5}
   \end{subfigure}
  \begin{subfigure}[b]{0.85\textwidth}
       \centering
       \includegraphics[width=\textwidth]{data/load_vectoradd_nexus7.pdf}
       \caption{VectorAdd on Nexus 7}\label{fig:Vecadd7}
   \end{subfigure}

  \begin{subfigure}[b]{0.85\textwidth}
       \centering
       \includegraphics[width=\textwidth]{data/load_sgemm_nexus5.pdf}
       \caption{Sgemm on Nexus 5}\label{fig:Sgemm5}
   \end{subfigure}
  \begin{subfigure}[b]{0.85\textwidth}
       \centering
       \includegraphics[width=\textwidth]{data/load_sgemm_nexus7.pdf}
       \caption{Sgemm on Nexus 7}\label{fig:Sgemm7}
   \end{subfigure}


  \caption{Processor utilization of VectorAdd and SGEMM for both Nexus 5 and Nexus 7. The $x$ axis is time, and the $y$ axis is normalized to the peek utlization for CPUs or GPUs across implementations.}
  \label{fig:loadVecAddSgemm}
\end{figure*}
\FloatBarrier

Mobile devices use dynamic voltage frequency scaling (DVFS)
  to match performance to power utlization.
The frequency is increased for the processors when the load goes over a certain
  threashold.
Both CPUs and GPUs make use of frequency scaling, but unlike CPUs (which typically
  have vary fine frequencies --- operating at around 10 different frequencies), GPUs
  have coarse grained frequencies (operating at only 4 different frequencies).  

Processor utlization is measured by multiplying the $frequency$ and the $load$ information collected via Qualcomm's Trepn tool.
The performance times are measured with the system connected to a
  power source, which avoids the device going to sleep (it does add the
  overhead of the device comunicating debug information with the development
  machine).
Since Trepn has a $100ms$ measure granularity, the kernel code is run $100$ times
  ($5$ times for MRIQ and TPACF), this allows us to visualize the trend in resource
  utlization.
The information gives us insight as to what parts of the code are active in each
	section of the code, how that impacts performance and battery.


Note that Java UI thread is running independent of the computation as well as Trepn which
  have a high overhead ($10\%$ on average).
These background processes are echoed in
  the plots --- a single threaded Java code, for example, should not utilize more than one core, but our plots show that more than one core is active.


VectorAdd has a very high memory to compute ratio, therefore the processor utlization
  plot~(figure \ref{fig:loadVecAddSgemm}) shows that not all CPUs 
  are fully utlized during the compute phase.
For the Nexus 5 device, while the graphs show a GPU is being used during the OpenMP,
  Renderscript, and Java, this is an error in the measurement --- we believe this is 
  due to the UI thread utilizing the GPU or some other interferences.
As expected, the GPU is not being utilized on the Nexus 7 except for OpenCL.

As discussed in the benchmark section, the Android GCC compiler was not able 
  to interpret the OpenMP pragma code and therefore SGEMM runs in a single thread
  on both the Nexus 5 and Nexus 7 (figure~\ref{fig:loadVecAddSgemm}).
While OpenCL does utlize the GPU, because of the size of the matrix, there GPU has
  lower occupancy and therefore does not achieve peek performance.
Both the RenderScript and ThreadedJava code make full utlization of all the cores.

MRIQ is embarisingly parallel and we can see full utlization for both the CPUs and GPUs in figure~\ref{fig:loadMRIQTpacf}.
Abrupt dips in the plots show positions where a kernel launch occurs.
It is also interesting to note that on the Nexus 5 the CPU is not fully utilized for both ThreadedJava and Renderscript.
This is due to either the load being low for a high frequency or the frequency being 
  choosen to be low.

\begin{figure*}[t]
  \centering

  \begin{subfigure}[b]{\textwidth}
          \centering
          \includegraphics[width=0.4\textwidth]{data/load_legend.pdf}
  \end{subfigure}

  \begin{subfigure}[b]{0.95\textwidth}
      \centering
      \includegraphics[width=\textwidth]{data/load_mriq_nexus5.pdf}
      \caption{MRIQ on Nexus 5}
      \label{fig:MRIQ5}
  \end{subfigure}
  \begin{subfigure}[b]{0.95\textwidth}
      \centering
      \includegraphics[width=\textwidth]{data/load_mriq_nexus7.pdf}
      \caption{MRIQ on Nexus 7}
      \label{fig:MRIQ7}
  \end{subfigure}

  \begin{subfigure}[b]{0.95\textwidth}
      \centering
      \includegraphics[width=\textwidth]{data/load_tpacf_nexus5.pdf}
      \caption{TPACF on Nexus 5}
      \label{fig:TPACF5}
  \end{subfigure}
  \begin{subfigure}[b]{0.95\textwidth}
      \centering
      \includegraphics[width=\textwidth]{data/load_tpacf_nexus7.pdf}
      \caption{TPACF on Nexus 7}
      \label{fig:TPACF7}
  \end{subfigure}

  \caption{Processor utilization of MRIQ and TPACF for both Nexus 5 and Nexus 7. The $x$ axis is time, and the $y$ axis is normalized to the peek utlization for CPUs or GPUs across implementations.}
  \label{fig:loadMRIQTpacf}
\end{figure*}
\FloatBarrier

The TPACF compute codes is divided into two parts.
The first is serial computation that, for the sake of code reuse, is done on the 
  Java side using a single thread.
Once that complets, we then execute the code on different datasets in parallel.
The utlization plots (figure~\ref{fig:loadMRIQTpacf}) show this behavior.  

For Histogram (figure~\ref{fig:loadHistogramStencil}) we see that memory starts
  to play a major role in processor utlization.
The GPU is being utlized in the memory copy as it is in the computation, for example.

For Stencil (figure~\ref{fig:loadHistogramStencil}) we see that RenderScript does
  not fully utilize all CPU cores.
This is because the stencil kernel is memory access bound, performing around 10 flops 
  (ignoring index calculations).
We again see that memory copy (\fix{SetupArgs} for RenderScript and
  \fix{CopyTo} for OpenCL) result in the a substantial amound of resources being
  wasted.

\begin{figure*}[t]
  \centering

  \begin{subfigure}[b]{\textwidth}
          \centering
          \includegraphics[width=0.4\textwidth]{data/load_legend.pdf}
  \end{subfigure}

  \begin{subfigure}[b]{0.9\textwidth}
      \centering
      \includegraphics[width=\textwidth]{data/load_histogram_nexus5.pdf}
      \caption{Histogram on Nexus 5}
      \label{fig:Histogram5}
  \end{subfigure}
  \begin{subfigure}[b]{0.9\textwidth}
      \centering
      \includegraphics[width=\textwidth]{data/load_stencil_nexus5.pdf}
      \caption{Stencil on Nexus 5}
      \label{fig:Stencil5}
  \end{subfigure}

  \caption{Processor utilization of Histogram and Stencil for both Nexus 5. The $x$ axis is time, and the $y$ axis is normalized to the peek utlization for CPUs or GPUs across implementations.}
  \label{fig:loadHistogramStencil}
\end{figure*}
\FloatBarrier

Throughout the benchmarks we see that RenderScript
	does not utalize the GPU.
This is due to RenderScript requiring full
	IEEE 754-2008 compliance, which the GPU is not able to provide.
Inserting the \fix{\#pragma rs\_fp\_imprecise} pragma into the
	RenderScript kernel allows for relaxed IEEE compliance and 
	should allow for GPU acceleration.
Similar options are available in OpenCL and C, but since
	this option is not available in Java we chose to disable it. 
Further investigations would require us to analyze the results with relatex precision.

