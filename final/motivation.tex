\section{Motivation and Background}
\todo[inline]{Assuming Introduction has a sentence or two about the
programmability problem.}
The industry and the research community have been trying to solve this problem.
The recent development of RenderScript~\cite{wiki:RenderScript, RenderScript}
provides a framework
for running computationally intensive tasks at a high performance by using a
specialized runtime for 
parallelizing work across all processors available on the device, such as
multi-core CPUs, GPUs, or DSPs. RenderScript is therefore removing the
burden of load balancing and memory management from the programmer to the run-time, unlike other
solutions such as OpenCL, where the programmer has more control over the
execution semantics of the application ({\em the programmer decides which part
of application would run on which device and using which part of the memory heirarchy}).
In this fashion RenderScript is
making the computationally intensive part of the application, that needs to be
accelerated on specialized hardware, performance portable across the various hardware compute
units. Also, since the application is not dependent on the existence and
availability of a specific accelerator, the application is portable across SoCs
with varying combinations of compute units.

While such portability is a noble goal, RenderScript achieves it at the cost of
hiding hardware details from the programmer that are critical to good
performance on these accelerator. For example, in GPUs, the placement of data at
various levels of memory hierarchy is critical to good performance.
It is this reason that most programming languages for GPUs, allow the programmer
unlimited control over memory management. RenderScript too can use GPUs for acceleration, but
completely hides the memory management from the programmer. In the RenderScript
model, application developers only define the part of the application that needs
to be accelerated, and the granularity at which data needs to be partitioned,
while the rest of the responsibilities of memory management and work distribution
among different compute units is handled by RenderScript compiler and run-time.
This raises an important
question of ``how effective is the RenderScript compiler and run-time?'', which
we plan to answer by doing a comprehensive performance analysis of RenderScript.

\subsection{OpenCL}
OpenCL was initiated by Apple Inc. and is managed by the Khronos
Group~\cite{Khronos:url}. It allows the application developers to write
data parallel computation intensive parts of their application for an abstract
hardware model, without using low level hardware specific function calls.

An OpenCL application is composed of two parts: an OpenCL host program and a
set of one or more kernels. The kernels, written in restricted C99 syntax,
specify functions that are to be executed in data parallel fashion. The OpenCL
host program identifies the device on which the OpenCL kernel would be
executed, sets up the environment, allocate memory on the device, copy data
into the device memory and enqueue the kernel execution on the device.

In the Android world, where all application execute on Dalvik virtual machine,
an application using OpenCL has a third component as well. This is the Java
host code which would initialize the application, read in the inputs and use
JNI calls to invoke OpenCL host code.

OpenCL is designed to be portable across a wide range of devices. However,
developers often use hardware specific parameters such as the size of OpenCL
work-group, shared memory size to obtain better performance on specific
hardware. This harms the portability of OpenCL application kernel code.

\subsection{RenderScript}
RenderScript was released by Google as an official computing framework in
2011~\cite{RederScript:url}. The motivation behind RenderScript is to provide
performance and portability across SoC architectures to RenderScript
applications.

A RenderScript application consists of three parts: (1) Java application host
code written by the developer that runs on Dalvik VM, (2) RenderScript code
written in restricted C99 syntax containing one or more kernels, and (3)
auto-generated Java code that helps application host code to communicate with
RenderScript kernel code, allowing functions such as memory binding between the
host program and the kernels.

RenderScript compilation flow is shown in Figure~\ref{fig:RSCompilation}.
First, \fix{llvm-rs-cc} utility is used to compile RenderScript kernels to
LLVM~\ref{LLVM:url} bitcode (\fix{*.bc extension}) files. LLVM bitcode is LLVM
intermediate representation having backend support for a wide range of hardware
devices including general purpose processors, GPUs and DSPs. All OpenCL
compilers too use a subset of LLVM IR as intermediate representation, thus
making it a natural choice for RenderScript IR which has portability as one of
its primary goal. During compilation of RenderScript kernels, \fix{llvm-rs-cc}
also generates the corresponding reflected Java classes of the kernels.
Thereafter, the application host code, the reflected Java classes and bitcode
are bundled together into the Android application package (\fix{*.apk} file),
which is installed on the Android device. During execution, the RenderScript
runtime invokes \fix{libbcc}, RenderScript back-end compiler to translate
bitcode into appropriate machine code.


\todo[inline]{Programmability Challenge: Elaborate on that}
\todo[inline]{LLVM IR code snippet}
\lstinputlisting[language=llvm]{code/average.ll}
\lstinputlisting[language=llvm]{code/simple-gpu.ll}
